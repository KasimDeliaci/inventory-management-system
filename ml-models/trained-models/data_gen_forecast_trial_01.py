# -*- coding: utf-8 -*-
"""Data_Gen_Forecast_Trial_00.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AWx9w0-wEy6bwMj-e-BW1JNDiGWhcwSI
"""

import pandas as pd
import numpy as np
import random
from datetime import datetime, timedelta
import holidays
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error
from xgboost import XGBRegressor

"""#Data Generation"""

# Parameters
n_years = 3
n_days = 365 * n_years
start_date = datetime(2023, 1, 1)
end_date = start_date + timedelta(days=n_days - 1)

# Expanded product categories
products = [
    "candy", "electronics", "meat", "flowers",
    "soft_drinks", "sunscreen", "notebook", "toys"
]

# Holiday-product demand multipliers
holiday_effects = {
    "Ramazan BayramÄ±": {"candy": 2.0, "soft_drinks": 1.5},
    "Kurban BayramÄ±": {"meat": 1.8},
    "YÄ±lbaÅŸÄ±": {"electronics": 1.6, "toys": 2.0},
    "Sevgililer GÃ¼nÃ¼": {"flowers": 2.5, "candy": 1.8}
}

turkey_holidays = holidays.Turkey(years=range(start_date.year, end_date.year + 1))

#Arrangements
def generate_campaign():
    """Generate a campaign type, discount ratio, and duration."""
    c_type = random.choice([0, 1, 2])  # 0=discount,1=campaign,2=special offer
    if c_type == 0:
        ratio = round(np.random.uniform(0.05, 0.30), 2)
    elif c_type == 1:
        ratio = round(np.random.uniform(0.10, 0.50), 2)
    else:
        ratio = round(np.random.uniform(0.20, 0.70), 2)
    duration = random.randint(3, 14)
    return c_type, ratio, duration

def get_holiday_type(date):
    """Classify date as workday/public holiday/weekend."""
    if date in turkey_holidays:
        return 1  # Public holiday
    elif date.weekday() >= 5:
        return 2  # Weekend
    else:
        return 0  # Workday

def get_holiday_name(date):
    """Return holiday name if applicable."""
    return turkey_holidays.get(date)

def get_holiday_multiplier(product, holiday_name):
    """Return stochastic multiplier for product demand during a holiday (Poisson-based)."""
    if holiday_name in holiday_effects and product in holiday_effects[holiday_name]:
        lam = holiday_effects[holiday_name][product]
        val = np.random.poisson(lam)
        return max(val, 1)  # ensure â‰¥ 1
    return 1

def apply_seasonality(product, date, demand):
    """Apply seasonal effects based on product and month."""
    month = date.month

    if product == "sunscreen" and month in [6, 7, 8]:
        demand *= np.random.uniform(1.3, 1.7)
    elif product == "notebook" and month == 9:
        demand *= np.random.uniform(1.8, 2.2)
    elif product == "toys" and month == 12:
        demand *= np.random.uniform(1.8, 2.2)
    elif product == "flowers" and month in [3, 4, 5]:
        demand *= np.random.uniform(1.3, 1.6)
    elif product == "meat" and month in [11, 12, 1, 2]:
        demand *= np.random.uniform(1.1, 1.3)
    elif product == "soft_drinks" and month in [6, 7, 8]:
        demand *= np.random.uniform(1.3, 1.5)

    return demand

data = []

for pid, product in enumerate(products, start=1):
    current_date = start_date

    while current_date <= end_date:
        c_type, ratio, duration = generate_campaign()

        for d in range(duration):
            date = current_date + timedelta(days=d)
            if date > end_date:
                break

            base_demand = np.random.randint(50, 200)

            # Apply campaign
            demand = base_demand * (1 + ratio)

            # Weekend/holiday effects
            h_type = get_holiday_type(date)
            holiday_name = get_holiday_name(date)

            if h_type == 2:   # weekend
                demand *= 1.1
            elif h_type == 1: # public holiday
                demand *= 1.2

            if holiday_name:
                demand *= get_holiday_multiplier(product, holiday_name)

            demand = apply_seasonality(product, date, demand)

            # Add noise safely
            demand = max(int(np.random.normal(demand, 10)), 0)

            cci = round(np.random.normal(100, 5), 2)

            data.append([
                pid,
                product,
                date,
                demand,
                c_type,
                ratio,
                duration,
                h_type,
                cci,
                holiday_name if holiday_name else "None"
            ])

        # ðŸ”¹ move current_date forward by campaign duration
        current_date += timedelta(days=duration)

#Create DF
columns = [
    "product_id", "product_name", "date", "demand",
    "campaign_type", "discount_ratio", "campaign_duration",
    "holiday_type", "consumer_confidence_index", "holiday_name"
]

df = pd.DataFrame(data, columns=columns)

df.to_csv("synthetic_demand_data_4years_seasonal_poisson.csv", index=False)

print(df.head(20))
print("Total rows:", len(df))

df.shape

"""#1 Day Forecasting with XGBoost"""

df = pd.read_csv("synthetic_demand_data_4years_seasonal_poisson.csv", parse_dates=["date"])

# Lag features (important for time-series!)
df["lag_1"] = df.groupby("product_id")["demand"].shift(1)
df["lag_7"] = df.groupby("product_id")["demand"].shift(7)
df["rolling_mean_7"] = df.groupby("product_id")["demand"].shift(1).rolling(7).mean()

# Date features
df["day_of_week"] = df["date"].dt.weekday
df["month"] = df["date"].dt.month

# Encode categorical variables
df["campaign_type"] = df["campaign_type"].astype("category")
df["holiday_type"] = df["holiday_type"].astype("category")
df["product_id"] = df["product_id"].astype("category")

df.tail()

df = df.dropna()

x = df.drop(columns=["demand", "date", "holiday_name", "product_name"])
y = df["demand"]

train_mask = df["date"] < (df["date"].max() - pd.Timedelta(days=30))
x_train, x_test = x[train_mask], x[~train_mask]
y_train, y_test = y[train_mask], y[~train_mask]

model = XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    enable_categorical = True
)

model.fit(x_train, y_train)

y_pred = model.predict(x_test)
rmse = np.sqrt(mean_squared_error(y_test, y_pred))

print(f"Test RMSE: {rmse:.2f}")

results = pd.DataFrame({
    "date": df.loc[~train_mask, "date"],
    "product_id": df.loc[~train_mask, "product_id"],
    "actual_demand": y_test,
    "predicted_demand": y_pred
})
print(results.head(15))

import matplotlib.pyplot as plt

#plot the training and data preds
#1 day forecast
grouped = results.groupby('product_id')

for product, data in grouped:
    plt.figure(figsize=(12, 6))
    plt.plot(data['date'], data['actual_demand'], label='Actual Demand', marker='o')
    plt.plot(data['date'], data['predicted_demand'], label='Predicted Demand', marker='x')
    plt.title(f'Actual vs Predicted Demand for Product {product}')
    plt.xlabel('Date')
    plt.ylabel('Demand')
    plt.xticks(rotation=45)
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

"""#7 Day Forecasting wiht XGBoost"""

df02 = pd.read_csv("synthetic_demand_data_4years_seasonal_poisson.csv", parse_dates=["date"])

df02["lag_1"] = df02.groupby("product_id")["demand"].shift(1)
df02["lag_7"] = df02.groupby("product_id")["demand"].shift(7)
df02["rolling_mean_7"] = df02.groupby("product_id")["demand"].shift(1).rolling(7).mean()

df02["day_of_week"] = df02["date"].dt.weekday
df02["month"] = df02["date"].dt.month

# Encode categorical columns as integers
for col in ["product_id", "campaign_type", "holiday_type"]:
    df02[col] = df02[col].astype("category").cat.codes

df02.dropna()

# CREATE MULTI-OUTPUT TARGET (7-DAY HORIZON)
horizon = 7
targets = []
for i in range(1, horizon + 1):
    df02[f"target_t+{i}"] = df02.groupby("product_id")["demand"].shift(-i)
    targets.append(f"target_t+{i}")

df02 = df02.dropna()

x02 = df02.drop(columns=["demand", "date", "holiday_name", "product_name"] + targets)
y02 = df02[targets]

train_mask = df02["date"] < (df02["date"].max() - pd.Timedelta(days=30))
x02_train, x02_test = x02[train_mask], x02[~train_mask]
y02_train, y02_test = y02[train_mask], y02[~train_mask]

model = XGBRegressor(
    n_estimators=500,
    learning_rate=0.05,
    max_depth=6,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)

models = {}
for i, target in enumerate(targets, start=1):
    m = model.fit(x02_train, y02_train[target])
    models[target] = m

preds = {}
for target, m in models.items():
    preds[target] = m.predict(x02_test)

preds = pd.DataFrame(preds, index=x02_test.index)

# Calculate RMSE per horizon step
for target in targets:
    rmse = np.sqrt(mean_squared_error(y02_test[target], preds[target]))
    print(f"RMSE for {target}: {rmse:.2f}")

results = pd.concat([df02.loc[x02_test.index, ["date", "product_id"]], y02_test, preds], axis=1)
print(results.head(14))

#7 days forecast
horizon = preds.columns
plt.figure(figsize=(16,8))

for i, col in enumerate(horizon, start=1):
    plt.plot(y02_test.index, y02_test[col], label=f'Actual t+{i}', linestyle='--')
    plt.plot(preds.index, preds[col], label=f'Predicted t+{i}', alpha=0.7)

plt.xlabel('Date Index')
plt.ylabel('Demand')
plt.title('XGBoost Multi-step Forecast (7-day horizon)')
plt.legend()
plt.show()

"""#SARIMAX Forecasting Model"""

from statsmodels.tsa.statespace.sarimax import SARIMAX
from sklearn.metrics import mean_squared_error

df03 = pd.read_csv("synthetic_demand_data_4years_seasonal_poisson.csv", parse_dates=["date"])
df03 = df03.sort_values(["product_id", "date"])

# Choose a single product for SARIMAX (SARIMAX works best on single time-series)
product_id = 1
product_df03 = df03[df03["product_id"] == product_id].set_index("date")

target = product_df03["demand"]
exog_features = ["campaign_type", "discount_ratio", "campaign_duration",
                 "holiday_type", "consumer_confidence_index"]
exog = product_df03[exog_features]

# Split train/test (last 30 days as test)
train_target = target[:-30]
test_target = target[-30:]
train_exog = exog[:-30]
test_exog = exog[-30:]

model = SARIMAX(
    train_target,
    exog=train_exog,
    order=(1,1,1),
    seasonal_order=(1,1,1,7),
    enforce_stationarity=False,
    enforce_invertibility=False
)

model_fit = model.fit(disp=False)
print(model_fit.summary())

#Forecast
forecast = model_fit.get_forecast(steps=30, exog=test_exog)
forecast_mean = forecast.predicted_mean
forecast_ci = forecast.conf_int()

rmse = np.sqrt(mean_squared_error(test_target, forecast_mean))
print(f"Test RMSE: {rmse:.2f}")

results = pd.DataFrame({
    "actual": test_target,
    "forecast": forecast_mean
})
print(results.head(15))

plt.figure(figsize=(12,5))
plt.plot(train_target.index, train_target, label="Train")
plt.plot(test_target.index, test_target, label="Actual")
plt.plot(test_target.index, forecast_mean, label="Forecast")
plt.fill_between(test_target.index, forecast_ci.iloc[:,0], forecast_ci.iloc[:,1], color='pink', alpha=0.3)
plt.legend()
plt.show()

"""#LSTM Model"""

from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense

df04 = pd.read_csv("synthetic_demand_data_4years_seasonal_poisson.csv", parse_dates=["date"])
df04 = df04.sort_values(["product_id", "date"])

product_id = 1
product_df04 = df04[df04["product_id"] == product_id].set_index("date")

features = ["campaign_type", "discount_ratio", "campaign_duration",
            "holiday_type", "consumer_confidence_index"]
target = "demand"

#Scaling
scaler_X = MinMaxScaler()
scaler_y = MinMaxScaler()

X_scaled = scaler_X.fit_transform(product_df04[features])
y_scaled = scaler_y.fit_transform(product_df04[[target]])

def create_sequences(X, y, seq_length=14, horizon=7):
    X_seq, y_seq = [], []
    for i in range(len(X) - seq_length - horizon + 1):
        X_seq.append(X[i:i+seq_length])
        y_seq.append(y[i+seq_length:i+seq_length+horizon])
    return np.array(X_seq), np.array(y_seq)

SEQ_LENGTH = 14  # look-back 14 days
HORIZON = 7      # predict next 7 days

X_seq, y_seq = create_sequences(X_scaled, y_scaled, SEQ_LENGTH, HORIZON)

# TRAIN/TEST SPLIT
split = int(len(X_seq) * 0.9)
X_train, X_test = X_seq[:split], X_seq[split:]
y_train, y_test = y_seq[:split], y_seq[split:]

model = Sequential()
model.add(LSTM(64, activation='relu', input_shape=(SEQ_LENGTH, X_train.shape[2])))
model.add(Dense(HORIZON))
model.compile(optimizer='adam', loss='mse')

# TRAIN MODEL
history = model.fit(X_train, y_train, epochs=50, batch_size=16,
                    validation_split=0.1, verbose=1)

#prediction
y_pred_scaled = model.predict(X_test)
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, HORIZON))

y_test_actual = scaler_y.inverse_transform(y_test.reshape(-1, HORIZON))

# Compute RMSE per horizon step
for i in range(HORIZON):
    rmse = np.sqrt(mean_squared_error(y_test_actual[:, i], y_pred[:, i]))
    print(f"RMSE t+{i+1}: {rmse:.2f}")

plt.figure(figsize=(14,6))
plt.plot(y_test_actual[:,0], label='Actual t+1')
plt.plot(y_pred[:,0], label='Predicted t+1')
plt.xlabel('Samples')
plt.ylabel('Demand')
plt.title('LSTM Forecast - Day 1 of 7-step horizon')
plt.legend()
plt.show()

